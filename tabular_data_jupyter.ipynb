{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('listing.csv')\n",
    "df2 = pd.read_csv('listing.csv')\n",
    "\n",
    "# def remove_rows_with_missing_rating():\n",
    "#     df2=df.dropna(subset=['Cleanliness_rating','Accuracy_rating','Communication_rating', 'Location_rating','Check-in_rating','Value_rating'])\n",
    "#     print(df2.head(n=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_rows_with_missing_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_empty= [x for x in df['Description'][0[x for x in strings if x.strip()]list(filter(\"\", df['Description'][0]))\n",
    "# [x for x in df['Description'][0] if x.strip()]\n",
    "[x for x in df['Description'][0] if x]\n",
    "# ''.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Description'] = df['Description'].str.replace(r'\\s+', ' ')\n",
    "df2['Description'] = df['Description'].str.replace(r'About this space', '')\n",
    "df2['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_rating(df):\n",
    "    if 'guests' in df.columns:\n",
    "        df_cleaned = df[~df['guests'].astype(str).str.contains('Somerford Keynes England Unit')]\n",
    "    else:\n",
    "        df_cleaned = df.copy()\n",
    "    \n",
    "    numeric_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating', 'Location_rating', 'Check-in_rating', 'Value_rating']\n",
    "    \n",
    "    # Convert textual entries to 1 in numerical columns\n",
    "    for column in numeric_columns:\n",
    "        df_cleaned[column] = pd.to_numeric(df_cleaned[column], errors='coerce').fillna(1)\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    df_cleaned = df_cleaned.dropna(subset=numeric_columns)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def combine_description_strings(df):\n",
    "    df['Description'] = df['Description'].str.replace(r'\\s+', ' ')\n",
    "    df['Description'] = df['Description'].str.replace(r'About this space', '')\n",
    "    return df\n",
    "\n",
    "def set_default_values(df):\n",
    "    df['guests'] = df['guests'].fillna(1)\n",
    "    df['beds'] =  df['beds'].fillna(1)\n",
    "    df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def clean_tabular_data(df):\n",
    "    df1= remove_rows_with_missing_rating(df)\n",
    "    df2= combine_description_strings(df1)\n",
    "    dfClean= set_default_values(df2)\n",
    "\n",
    "    # # Use SimpleImputer with mean strategy for missing values\n",
    "    # imputer = SimpleImputer(strategy='mean')\n",
    "    # dfClean = imputer.fit_transform(df2)\n",
    "    return dfClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('listing.csv')\n",
    "dfClean = clean_tabular_data(df0)\n",
    "dfClean.to_csv('listingClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['beds'] =  df['beds'].fillna(1)\n",
    "df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "df['bathrooms'][4]\n",
    "# print(df['beds'].head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airbnb(label='Price_Night'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    \n",
    "    # Filter out columns with text data\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms', 'Price_Night']\n",
    "    df_numerical = df[numerical_columns]\n",
    "\n",
    "    # df_cleaned = df_numerical[~df_numerical['guests'].str.contains('Somerford Keynes England Unit', na=False)]\n",
    "    df_cleaned = df_numerical[~df['guests'].apply(lambda x: isinstance(x, str) and 'Somerford Keynes England Unit' in x)]\n",
    "\n",
    "    \n",
    "    # Remove the label from the features and assign it as the labels\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    labels = df_cleaned[label]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cleanliness_rating  Accuracy_rating  Communication_rating  \\\n",
      "0                   4.6              4.7                   4.3   \n",
      "1                   4.3              4.7                   4.6   \n",
      "2                   4.2              4.6                   4.8   \n",
      "3                   4.8              4.9                   4.9   \n",
      "4                   NaN              NaN                   NaN   \n",
      "..                  ...              ...                   ...   \n",
      "983                 4.8              5.0                   4.9   \n",
      "984                 4.8              5.0                   5.0   \n",
      "985                 4.7              4.8                   5.0   \n",
      "986                 NaN              NaN                   NaN   \n",
      "987                 4.9              4.9                   4.9   \n",
      "\n",
      "     Location_rating  Check-in_rating  Value_rating  beds  bathrooms  \n",
      "0                5.0              4.3           4.3   1.0        1.0  \n",
      "1                4.9              4.7           4.5   3.0        0.0  \n",
      "2                4.8              4.8           4.7   2.0        1.5  \n",
      "3                4.9              5.0           4.6   NaN        1.0  \n",
      "4                NaN              NaN           NaN   1.0        NaN  \n",
      "..               ...              ...           ...   ...        ...  \n",
      "983              4.9              5.0           4.9   1.0        1.0  \n",
      "984              5.0              5.0           4.8   2.0        1.5  \n",
      "985              5.0              5.0           4.7   3.0        2.0  \n",
      "986              NaN              NaN           NaN   7.0        5.0  \n",
      "987              4.9              4.9           4.3   2.0        1.0  \n",
      "\n",
      "[987 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_airbnb()\n",
    "# Filter only numeric columns\n",
    "# numerical_columns = features.select_dtypes(include=['float64', 'float32', 'int64', 'int32']).columns\n",
    "# features_numeric = features[numerical_columns]\n",
    "\n",
    "\n",
    "# Split dataset into train, validation, and test sets using train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(train_features, train_labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Print column names\n",
    "print(\"Train Features Columns:\", train_features.columns)\n",
    "\n",
    "# Check for non-numeric values in train_features\n",
    "non_numeric_rows = train_features[~train_features.applymap(np.isreal).all(1)]\n",
    "print(\"Non-Numeric Rows in Train Features:\")\n",
    "print(non_numeric_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airbnb(label='Price_Night'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    \n",
    "    # Filter out columns with text data\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms', 'Price_Night']\n",
    "    df_numerical = df[numerical_columns]\n",
    "\n",
    "    df_cleaned = df_numerical[~df_numerical['guests'].str.contains('Somerford Keynes England Unit', na=False)]\n",
    "\n",
    "    \n",
    "    # Remove the label from the features and assign it as the labels\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    labels = df_cleaned[label]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "features, labels = load_airbnb()\n",
    "# print(labels)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset with 'price_night' as the label\n",
    "features, labels = load_airbnb()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "# y_train_imputed = imputer.fit_transform(X_train)\n",
    "# y_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train a linear regression model using SGDRegressor\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = model.predict(X_train_imputed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calculate RMSE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate R^2 for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R^2 for test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"RMSE - Training Set:\", rmse_train)\n",
    "print(\"RMSE - Test Set:\", rmse_test)\n",
    "print(\"R^2 - Training Set:\", r2_train)\n",
    "print(\"R^2 - Test Set:\", r2_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE - Training Set: 207.30014764143422\n",
      "RMSE - Test Set: 95.78039559415649\n",
      "R^2 - Training Set: 0.19909675944990746\n",
      "R^2 - Test Set: 0.11633774520988349\n",
      "Mean Squared Error: 9173.88418017311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Load the dataset with 'price_night' as the label\n",
    "features, labels = load_airbnb()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train a linear regression model using SGDRegressor\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Make predictions on the training set\n",
    "y_train_pred = model.predict(X_train_imputed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calculate RMSE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate R^2 for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R^2 for test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"RMSE - Training Set:\", rmse_train)\n",
    "print(\"RMSE - Test Set:\", rmse_test)\n",
    "print(\"R^2 - Training Set:\", r2_train)\n",
    "print(\"R^2 - Test Set:\", r2_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, X_test_imputed, y_train, y_test\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    # Train your model here\n",
    "    model = SGDRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "    # Evaluate the model using mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Evaluate your model and return metrics\n",
    "    y_train_pred = model.predict(X_train_imputed)\n",
    "    y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return rmse_train, rmse_test, r2_train, r2_test, mse\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train_imputed, X_test_imputed, y_train, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train_imputed, y_train)\n",
    "\n",
    "    # Evaluate and print metrics\n",
    "    rmse_train, rmse_test, r2_train, r2_test, mse = evaluate_model(model, X_train_imputed, X_test_imputed, y_train, y_test)\n",
    "    \n",
    "    print(\"RMSE - Training Set:\", rmse_train)\n",
    "    print(\"RMSE - Test Set:\", rmse_test)\n",
    "    print(\"R^2 - Training Set:\", r2_train)\n",
    "    print(\"R^2 - Test Set:\", r2_test)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def custom_tune_regression_model_hyperparameters(model_class, X_train, y_train, X_val, y_val, hyperparameter_ranges):\n",
    "    best_model = None\n",
    "    best_hyperparameters = {}\n",
    "    best_performance = {\n",
    "        \"validation_RMSE\": float('inf'),\n",
    "        \"validation_R2\": -float('inf')\n",
    "    }\n",
    "    \n",
    "    # Iterate over hyperparameter combinations\n",
    "    for hyperparams in hyperparameter_ranges:\n",
    "        model = train_model(model_class, hyperparams, X_train, y_train)\n",
    "        val_rmse, val_r2, mse = evaluate_model(model, X_val, y_val)\n",
    "        \n",
    "        # Update best model and performance metrics if necessary\n",
    "        if val_rmse < best_performance[\"validation_RMSE\"]:\n",
    "            best_model = model\n",
    "            best_hyperparameters = hyperparams\n",
    "            best_performance[\"validation_RMSE\"] = val_rmse\n",
    "            best_performance[\"validation_R2\"] = val_r2\n",
    "    \n",
    "    return best_model, best_hyperparameters, best_performance\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Define hyperparameter ranges for SGDRegressor\n",
    "    hyperparameter_ranges = [\n",
    "        {'alpha': 0.0001, 'max_iter': 1000},\n",
    "        {'alpha': 0.001, 'max_iter': 1000},\n",
    "        {'alpha': 0.01, 'max_iter': 1000}\n",
    "        # Add more hyperparameter combinations as needed\n",
    "    ]\n",
    "\n",
    "    # Perform custom hyperparameter tuning\n",
    "    best_model, best_hyperparameters, best_performance = custom_tune_regression_model_hyperparameters(\n",
    "        SGDRegressor, X_train, y_train, X_val, y_val, hyperparameter_ranges\n",
    "    )\n",
    "\n",
    "    # Evaluate and print metrics on the test set\n",
    "    test_rmse, test_r2, mse = evaluate_model(best_model, X_test, y_test)\n",
    "    best_performance[\"test_RMSE\"] = test_rmse\n",
    "    best_performance[\"test_R2\"] = test_r2\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "    print(\"Validation RMSE:\", best_performance[\"validation_RMSE\"])\n",
    "    print(\"Validation R2:\", best_performance[\"validation_R2\"])\n",
    "    print(\"Test RMSE:\", best_performance[\"test_RMSE\"])\n",
    "    print(\"Test R2:\", best_performance[\"test_R2\"])\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'max_iter': 1000}\n",
      "Test RMSE: 94.98065022348909\n",
      "Test R2: 0.048255840163700436\n",
      "Mean Squared Error: 9021.32391687678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, param_grid, X_train, y_train, X_val, y_val):\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and best hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_hyperparameters\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Define hyperparameter grid for SGDRegressor\n",
    "    param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [1000, 2000]\n",
    "        # Add more hyperparameters and values as needed\n",
    "    }\n",
    "\n",
    "    # Create and tune the model using GridSearchCV\n",
    "    sgd_model = SGDRegressor()\n",
    "    best_model, best_hyperparameters = tune_regression_model_hyperparameters(\n",
    "        sgd_model, param_grid, X_train, y_train, X_val, y_val\n",
    "    )\n",
    "    \n",
    "    # Train the best model using the full training data\n",
    "    final_model = train_model(best_model.__class__, best_hyperparameters, X_train, y_train)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    test_rmse, test_r2, mse = evaluate_model(final_model, X_test, y_test)\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "    print(\"Test RMSE:\", test_rmse)\n",
    "    print(\"Test R2:\", test_r2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision_tree - Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Test RMSE: 128.79202413823532\n",
      "Test R2: -0.749959030908445\n",
      "Mean Squared Error: 16587.385481623787\n",
      "Random_forest - Best Hyperparameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Test RMSE: 113.21524645229299\n",
      "Test R2: -0.35225867553657797\n",
      "Mean Squared Error: 12817.69202925344\n",
      "Gradient_boosting - Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Test RMSE: 87.47703755413889\n",
      "Test R2: 0.1926941902012138\n",
      "Mean Squared Error: 7652.232099248226\n",
      "Stochhastic_gradient_descent - Best Hyperparameters: {'alpha': 0.001, 'max_iter': 1000}\n",
      "Test RMSE: 111.2362009818063\n",
      "Test R2: -0.3053958870587705\n",
      "Mean Squared Error: 12373.492408864806\n",
      "Decision_tree - Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Test RMSE: 128.79202413823532\n",
      "Test R2: -0.749959030908445\n",
      "Mean Squared Error: 16587.385481623787\n",
      "Random_forest - Best Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Test RMSE: 113.95846546060227\n",
      "Test R2: -0.3700711734529294\n",
      "Mean Squared Error: 12986.53185013528\n",
      "Gradient_boosting - Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "Test RMSE: 86.90753221470604\n",
      "Test R2: 0.2031716450555705\n",
      "Mean Squared Error: 7552.919155650167\n",
      "Stochhastic_gradient_descent - Best Hyperparameters: {'alpha': 0.0001, 'max_iter': 1000}\n",
      "Test RMSE: 132.56040921456335\n",
      "Test R2: -0.8538629113029537\n",
      "Mean Squared Error: 17572.262091132492\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, param_grid, X_train, y_train, X_val, y_val):\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and best hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_hyperparameters\n",
    "\n",
    "def evaluate_all_models(features, labels):\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "    \n",
    "    # Define hyperparameter grids for each model\n",
    "    decision_tree_param_grid = {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    random_forest_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    gradient_boosting_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 10]\n",
    "    }\n",
    "    sgd_param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "    \n",
    "    # Models to evaluate\n",
    "    models = [\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        GradientBoostingRegressor(),\n",
    "        SGDRegressor()\n",
    "    ]\n",
    "    \n",
    "    for model in models:\n",
    "        if isinstance(model, DecisionTreeRegressor):\n",
    "            param_grid = decision_tree_param_grid\n",
    "            model_name = \"decision_tree\"\n",
    "        elif isinstance(model, RandomForestRegressor):\n",
    "            param_grid = random_forest_param_grid\n",
    "            model_name = \"random_forest\"\n",
    "        elif isinstance(model, GradientBoostingRegressor):\n",
    "            param_grid = gradient_boosting_param_grid\n",
    "            model_name = \"gradient_boosting\"\n",
    "        elif isinstance(model, SGDRegressor):\n",
    "            param_grid = sgd_param_grid\n",
    "            model_name = \"stochhastic_gradient_descent\"\n",
    "        else:\n",
    "            continue  # Skip unknown models\n",
    "        \n",
    "        # Tune and train the model using GridSearchCV\n",
    "        best_model, best_hyperparameters = tune_regression_model_hyperparameters(\n",
    "            model, param_grid, X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        \n",
    "        # Train the best model using the full training data\n",
    "        final_model = train_model(best_model.__class__, best_hyperparameters, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the final model on the test set\n",
    "        test_rmse, test_r2, mse = evaluate_model(final_model, X_test, y_test)\n",
    "        \n",
    "        # # Save the model, hyperparameters, and metrics\n",
    "        # folder_path = f\"models/regression/{model_name}\"\n",
    "        # save_model(final_model, best_hyperparameters, {\"test_RMSE\": test_rmse, \"test_R2\": test_r2, \"MSE\": mse}, folder_path)\n",
    "        \n",
    "        print(f\"{model_name.capitalize()} - Best Hyperparameters:\", best_hyperparameters)\n",
    "        print(\"Test RMSE:\", test_rmse)\n",
    "        print(\"Test R2:\", test_r2)\n",
    "        print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Evaluate all models\n",
    "    evaluate_all_models(features, labels)\n",
    "    print(type(evaluate_all_models(features,labels)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
