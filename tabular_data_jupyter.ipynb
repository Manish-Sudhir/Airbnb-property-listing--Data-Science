{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('listing.csv')\n",
    "df2 = pd.read_csv('listing.csv')\n",
    "\n",
    "# def remove_rows_with_missing_rating():\n",
    "#     df2=df.dropna(subset=['Cleanliness_rating','Accuracy_rating','Communication_rating', 'Location_rating','Check-in_rating','Value_rating'])\n",
    "#     print(df2.head(n=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_rows_with_missing_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_empty= [x for x in df['Description'][0[x for x in strings if x.strip()]list(filter(\"\", df['Description'][0]))\n",
    "# [x for x in df['Description'][0] if x.strip()]\n",
    "[x for x in df['Description'][0] if x]\n",
    "# ''.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Description'] = df['Description'].str.replace(r'\\s+', ' ')\n",
    "df2['Description'] = df['Description'].str.replace(r'About this space', '')\n",
    "df2['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_rating(df):\n",
    "    if 'guests' in df.columns:\n",
    "        df_cleaned = df[~df['guests'].astype(str).str.contains('Somerford Keynes England Unit')]\n",
    "    else:\n",
    "        df_cleaned = df.copy()\n",
    "    \n",
    "    numeric_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating', 'Location_rating', 'Check-in_rating', 'Value_rating']\n",
    "    \n",
    "    # Convert textual entries to 1 in numerical columns\n",
    "    for column in numeric_columns:\n",
    "        df_cleaned[column] = pd.to_numeric(df_cleaned[column], errors='coerce').fillna(1)\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    df_cleaned = df_cleaned.dropna(subset=numeric_columns)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def combine_description_strings(df):\n",
    "    df['Description'] = df['Description'].str.replace(r'\\s+', ' ')\n",
    "    df['Description'] = df['Description'].str.replace(r'About this space', '')\n",
    "    return df\n",
    "\n",
    "def set_default_values(df):\n",
    "    df['guests'] = df['guests'].fillna(1)\n",
    "    df['beds'] =  df['beds'].fillna(1)\n",
    "    df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def clean_tabular_data(df):\n",
    "    df1= remove_rows_with_missing_rating(df)\n",
    "    df2= combine_description_strings(df1)\n",
    "    dfClean= set_default_values(df2)\n",
    "\n",
    "    # # Use SimpleImputer with mean strategy for missing values\n",
    "    # imputer = SimpleImputer(strategy='mean')\n",
    "    # dfClean = imputer.fit_transform(df2)\n",
    "    return dfClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('listing.csv')\n",
    "dfClean = clean_tabular_data(df0)\n",
    "dfClean.to_csv('listingClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['beds'] =  df['beds'].fillna(1)\n",
    "df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "df['bathrooms'][4]\n",
    "# print(df['beds'].head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airbnb(label='Price_Night'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    \n",
    "    # Filter out columns with text data\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms', 'Price_Night']\n",
    "    df_numerical = df[numerical_columns]\n",
    "\n",
    "    # df_cleaned = df_numerical[~df_numerical['guests'].str.contains('Somerford Keynes England Unit', na=False)]\n",
    "    df_cleaned = df_numerical[~df['guests'].apply(lambda x: isinstance(x, str) and 'Somerford Keynes England Unit' in x)]\n",
    "\n",
    "    \n",
    "    # Remove the label from the features and assign it as the labels\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    labels = df_cleaned[label]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airbnb(label='Price_Night'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    \n",
    "    # Filter out columns with text data\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms', 'Price_Night']\n",
    "    df_numerical = df[numerical_columns]\n",
    "\n",
    "    df_cleaned = df_numerical[~df_numerical['guests'].str.contains('Somerford Keynes England Unit', na=False)]\n",
    "\n",
    "    \n",
    "    # Remove the label from the features and assign it as the labels\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    labels = df_cleaned[label]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "features, labels = load_airbnb()\n",
    "# print(labels)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset with 'price_night' as the label\n",
    "features, labels = load_airbnb()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "# y_train_imputed = imputer.fit_transform(X_train)\n",
    "# y_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train a linear regression model using SGDRegressor\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = model.predict(X_train_imputed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calculate RMSE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate R^2 for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R^2 for test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"RMSE - Training Set:\", rmse_train)\n",
    "print(\"RMSE - Test Set:\", rmse_test)\n",
    "print(\"R^2 - Training Set:\", r2_train)\n",
    "print(\"R^2 - Test Set:\", r2_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE - Training Set: 207.30014764143422\n",
      "RMSE - Test Set: 95.78039559415649\n",
      "R^2 - Training Set: 0.19909675944990746\n",
      "R^2 - Test Set: 0.11633774520988349\n",
      "Mean Squared Error: 9173.88418017311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Load the dataset with 'price_night' as the label\n",
    "features, labels = load_airbnb()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train a linear regression model using SGDRegressor\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Make predictions on the training set\n",
    "y_train_pred = model.predict(X_train_imputed)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calculate RMSE for test set\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate R^2 for training set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate R^2 for test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"RMSE - Training Set:\", rmse_train)\n",
    "print(\"RMSE - Test Set:\", rmse_test)\n",
    "print(\"R^2 - Training Set:\", r2_train)\n",
    "print(\"R^2 - Test Set:\", r2_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, X_test_imputed, y_train, y_test\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    # Train your model here\n",
    "    model = SGDRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "    # Evaluate the model using mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Evaluate your model and return metrics\n",
    "    y_train_pred = model.predict(X_train_imputed)\n",
    "    y_test_pred = model.predict(X_test_imputed)\n",
    "\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return rmse_train, rmse_test, r2_train, r2_test, mse\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train_imputed, X_test_imputed, y_train, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train_imputed, y_train)\n",
    "\n",
    "    # Evaluate and print metrics\n",
    "    rmse_train, rmse_test, r2_train, r2_test, mse = evaluate_model(model, X_train_imputed, X_test_imputed, y_train, y_test)\n",
    "    \n",
    "    print(\"RMSE - Training Set:\", rmse_train)\n",
    "    print(\"RMSE - Test Set:\", rmse_test)\n",
    "    print(\"R^2 - Training Set:\", r2_train)\n",
    "    print(\"R^2 - Test Set:\", r2_test)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def custom_tune_regression_model_hyperparameters(model_class, X_train, y_train, X_val, y_val, hyperparameter_ranges):\n",
    "    best_model = None\n",
    "    best_hyperparameters = {}\n",
    "    best_performance = {\n",
    "        \"validation_RMSE\": float('inf'),\n",
    "        \"validation_R2\": -float('inf')\n",
    "    }\n",
    "    \n",
    "    # Iterate over hyperparameter combinations\n",
    "    for hyperparams in hyperparameter_ranges:\n",
    "        model = train_model(model_class, hyperparams, X_train, y_train)\n",
    "        val_rmse, val_r2, mse = evaluate_model(model, X_val, y_val)\n",
    "        \n",
    "        # Update best model and performance metrics if necessary\n",
    "        if val_rmse < best_performance[\"validation_RMSE\"]:\n",
    "            best_model = model\n",
    "            best_hyperparameters = hyperparams\n",
    "            best_performance[\"validation_RMSE\"] = val_rmse\n",
    "            best_performance[\"validation_R2\"] = val_r2\n",
    "    \n",
    "    return best_model, best_hyperparameters, best_performance\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Define hyperparameter ranges for SGDRegressor\n",
    "    hyperparameter_ranges = [\n",
    "        {'alpha': 0.0001, 'max_iter': 1000},\n",
    "        {'alpha': 0.001, 'max_iter': 1000},\n",
    "        {'alpha': 0.01, 'max_iter': 1000}\n",
    "        # Add more hyperparameter combinations as needed\n",
    "    ]\n",
    "\n",
    "    # Perform custom hyperparameter tuning\n",
    "    best_model, best_hyperparameters, best_performance = custom_tune_regression_model_hyperparameters(\n",
    "        SGDRegressor, X_train, y_train, X_val, y_val, hyperparameter_ranges\n",
    "    )\n",
    "\n",
    "    # Evaluate and print metrics on the test set\n",
    "    test_rmse, test_r2, mse = evaluate_model(best_model, X_test, y_test)\n",
    "    best_performance[\"test_RMSE\"] = test_rmse\n",
    "    best_performance[\"test_R2\"] = test_r2\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "    print(\"Validation RMSE:\", best_performance[\"validation_RMSE\"])\n",
    "    print(\"Validation R2:\", best_performance[\"validation_R2\"])\n",
    "    print(\"Test RMSE:\", best_performance[\"test_RMSE\"])\n",
    "    print(\"Test R2:\", best_performance[\"test_R2\"])\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'max_iter': 1000}\n",
      "Test RMSE: 94.98065022348909\n",
      "Test R2: 0.048255840163700436\n",
      "Mean Squared Error: 9021.32391687678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, param_grid, X_train, y_train, X_val, y_val):\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and best hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_hyperparameters\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "\n",
    "    # Define hyperparameter grid for SGDRegressor\n",
    "    param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [1000, 2000]\n",
    "        # Add more hyperparameters and values as needed\n",
    "    }\n",
    "\n",
    "    # Create and tune the model using GridSearchCV\n",
    "    sgd_model = SGDRegressor()\n",
    "    best_model, best_hyperparameters = tune_regression_model_hyperparameters(\n",
    "        sgd_model, param_grid, X_train, y_train, X_val, y_val\n",
    "    )\n",
    "    \n",
    "    # Train the best model using the full training data\n",
    "    final_model = train_model(best_model.__class__, best_hyperparameters, X_train, y_train)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    test_rmse, test_r2, mse = evaluate_model(final_model, X_test, y_test)\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "    print(\"Test RMSE:\", test_rmse)\n",
    "    print(\"Test R2:\", test_r2)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 120\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(evaluate_all_models(features,labels)))\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 120\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[7], line 116\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m features, labels \u001b[39m=\u001b[39m load_airbnb()\n\u001b[1;32m    115\u001b[0m \u001b[39m# Evaluate all models\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m evaluate_all_models(features, labels)\n\u001b[1;32m    117\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(evaluate_all_models(features,labels)))\n",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m, in \u001b[0;36mevaluate_all_models\u001b[0;34m(features, labels)\u001b[0m\n\u001b[1;32m     62\u001b[0m sgd_param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m     63\u001b[0m     \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.0001\u001b[39m, \u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m],\n\u001b[1;32m     64\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_iter\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1000\u001b[39m, \u001b[39m2000\u001b[39m]\n\u001b[1;32m     65\u001b[0m }\n\u001b[1;32m     67\u001b[0m \u001b[39m# Models to evaluate\u001b[39;00m\n\u001b[1;32m     68\u001b[0m models \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 69\u001b[0m     DecisionTreeRegressor(),\n\u001b[1;32m     70\u001b[0m     RandomForestRegressor(),\n\u001b[1;32m     71\u001b[0m     GradientBoostingRegressor(),\n\u001b[1;32m     72\u001b[0m     SGDRegressor()\n\u001b[1;32m     73\u001b[0m ]\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, DecisionTreeRegressor):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "def preprocess_data(features, labels):\n",
    "    # Preprocess your data here (imputation, scaling, etc.)\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_val_imputed = imputer.transform(X_val)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    return X_train_imputed, y_train, X_val_imputed, y_val, X_test_imputed, y_test\n",
    "\n",
    "def train_model(model_class, hyperparameters, X_train, y_train):\n",
    "    # Initialize and train the model with given hyperparameters\n",
    "    model = model_class(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Evaluate the model and return performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return rmse, r2, mse\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, param_grid, X_train, y_train, X_val, y_val):\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and best hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_hyperparameters\n",
    "\n",
    "def evaluate_all_models(features, labels):\n",
    "    # Preprocess data and create validation set\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(features, labels)\n",
    "    \n",
    "    # Define hyperparameter grids for each model\n",
    "    decision_tree_param_grid = {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    random_forest_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    gradient_boosting_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 10]\n",
    "    }\n",
    "    sgd_param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "    \n",
    "    # Models to evaluate\n",
    "    models = [\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        GradientBoostingRegressor(),\n",
    "        SGDRegressor()\n",
    "    ]\n",
    "    \n",
    "    for model in models:\n",
    "        if isinstance(model, DecisionTreeRegressor):\n",
    "            param_grid = decision_tree_param_grid\n",
    "            model_name = \"decision_tree\"\n",
    "        elif isinstance(model, RandomForestRegressor):\n",
    "            param_grid = random_forest_param_grid\n",
    "            model_name = \"random_forest\"\n",
    "        elif isinstance(model, GradientBoostingRegressor):\n",
    "            param_grid = gradient_boosting_param_grid\n",
    "            model_name = \"gradient_boosting\"\n",
    "        elif isinstance(model, SGDRegressor):\n",
    "            param_grid = sgd_param_grid\n",
    "            model_name = \"stochhastic_gradient_descent\"\n",
    "        else:\n",
    "            continue  # Skip unknown models\n",
    "        \n",
    "        # Tune and train the model using GridSearchCV\n",
    "        best_model, best_hyperparameters = tune_regression_model_hyperparameters(\n",
    "            model, param_grid, X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        \n",
    "        # Train the best model using the full training data\n",
    "        final_model = train_model(best_model.__class__, best_hyperparameters, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the final model on the test set\n",
    "        test_rmse, test_r2, mse = evaluate_model(final_model, X_test, y_test)\n",
    "        \n",
    "        # # Save the model, hyperparameters, and metrics\n",
    "        # folder_path = f\"models/regression/{model_name}\"\n",
    "        # save_model(final_model, best_hyperparameters, {\"test_RMSE\": test_rmse, \"test_R2\": test_r2, \"MSE\": mse}, folder_path)\n",
    "        \n",
    "        print(f\"{model_name.capitalize()} - Best Hyperparameters:\", best_hyperparameters)\n",
    "        print(\"Test RMSE:\", test_rmse)\n",
    "        print(\"Test R2:\", test_r2)\n",
    "        print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'price_night' as the label\n",
    "    features, labels = load_airbnb()\n",
    "\n",
    "    # Evaluate all models\n",
    "    evaluate_all_models(features, labels)\n",
    "    print(type(evaluate_all_models(features,labels)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
