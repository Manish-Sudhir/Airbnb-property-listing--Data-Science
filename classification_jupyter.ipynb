{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Category', 'Title', 'Description', 'Amenities', 'Location',\n",
      "       'guests', 'beds', 'bathrooms', 'Price_Night', 'Cleanliness_rating',\n",
      "       'Accuracy_rating', 'Communication_rating', 'Location_rating',\n",
      "       'Check-in_rating', 'Value_rating', 'amenities_count', 'url', 'bedrooms',\n",
      "       'Unnamed: 19'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('listing.csv')\n",
    "df2 = pd.read_csv('listing.csv')\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_rating(df):\n",
    "    if 'guests' in df.columns:\n",
    "        df_cleaned = df[~df['guests'].astype(str).str.contains('Somerford Keynes England Unit')]\n",
    "    else:\n",
    "        df_cleaned = df.copy()\n",
    "    \n",
    "    numeric_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating', 'Location_rating', 'Check-in_rating', 'Value_rating']\n",
    "    \n",
    "    # Convert textual entries to 1 in numerical columns\n",
    "    for column in numeric_columns:\n",
    "        df_cleaned[column] = pd.to_numeric(df_cleaned[column], errors='coerce').fillna(1)\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    df_cleaned = df_cleaned.dropna(subset=numeric_columns)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def combine_description_strings(df):\n",
    "    df['Description'] = df['Description'].str.replace(r'\\s+', ' ')\n",
    "    df['Description'] = df['Description'].str.replace(r'About this space', '')\n",
    "    return df\n",
    "\n",
    "def set_default_values(df):\n",
    "    df['guests'] = df['guests'].fillna(1)\n",
    "    df['beds'] =  df['beds'].fillna(1)\n",
    "    df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Somerford Keynes England United Kingdom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m features, labels \u001b[39m=\u001b[39m load_airbnb(label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39m# Preprocess data\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m features_preprocessed \u001b[39m=\u001b[39m preprocess_data(features)\n\u001b[1;32m     44\u001b[0m \u001b[39m# The rest of your code for modeling and evaluation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     24\u001b[0m non_numeric_columns \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m features\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m numerical_columns]\n\u001b[1;32m     25\u001b[0m imputer \u001b[39m=\u001b[39m SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m features[numerical_columns] \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39;49mfit_transform(features[numerical_columns])\n\u001b[1;32m     28\u001b[0m \u001b[39m# Here, we'll drop non-numeric columns for simplicity\u001b[39;00m\n\u001b[1;32m     29\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39mnon_numeric_columns)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    382\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter was deprecated in version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m     )\n\u001b[0;32m--> 390\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    392\u001b[0m \u001b[39m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# otherwise\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:342\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(ve):\n\u001b[1;32m    337\u001b[0m     new_ve \u001b[39m=\u001b[39m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m strategy with non-numeric data:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    339\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, ve\n\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m     \u001b[39mraise\u001b[39;00m new_ve \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m ve\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Somerford Keynes England United Kingdom'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_airbnb(label='Category'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    \n",
    "    # Filter out rows with missing 'Category' values\n",
    "    df_cleaned = df.dropna(subset=[label])\n",
    "    \n",
    "    # Extract the label column\n",
    "    labels = df_cleaned[label]\n",
    "    \n",
    "    # Remove the label column from the features\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def preprocess_data(features):\n",
    "    # Impute missing values in numerical columns with the mean\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms']\n",
    "    non_numeric_columns = [col for col in features.columns if col not in numerical_columns]\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features[numerical_columns] = imputer.fit_transform(features[numerical_columns])\n",
    "    \n",
    "    # Here, we'll drop non-numeric columns for simplicity\n",
    "    features = features.drop(columns=non_numeric_columns)\n",
    "\n",
    "    # Perform any other preprocessing steps as needed\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ... The rest of your preprocessing and modeling code ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the dataset with 'Category' as the label\n",
    "    features, labels = load_airbnb(label='Category')\n",
    "    \n",
    "    # Preprocess data\n",
    "    features_preprocessed = preprocess_data(features)\n",
    "    \n",
    "    # The rest of your code for modeling and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '2797a470-75c0-4ee3-9184-95f59c977701'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Impute missing values in features\u001b[39;00m\n\u001b[1;32m     14\u001b[0m imputer \u001b[39m=\u001b[39m SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m X_train_imputed \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[1;32m     16\u001b[0m X_val_imputed \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39mtransform(X_val)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    382\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter was deprecated in version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m     )\n\u001b[0;32m--> 390\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    392\u001b[0m \u001b[39m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# otherwise\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:342\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(ve):\n\u001b[1;32m    337\u001b[0m     new_ve \u001b[39m=\u001b[39m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m strategy with non-numeric data:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    339\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, ve\n\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m     \u001b[39mraise\u001b[39;00m new_ve \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m ve\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '2797a470-75c0-4ee3-9184-95f59c977701'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from tabular_data import load_airbnb\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset with 'price_night' as the label\n",
    "features, labels = load_airbnb(label='Category')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Impute missing values in features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "model = LogisticRegression(max_iter=1000,random_state=42)\n",
    "model.fit(X_train_imputed,y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_val_pred = model.predict(X_val_imputed)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3265993265993266\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabular_data import load_airbnb\n",
    "\n",
    "# Load Airbnb data\n",
    "def load_airbnb(label='Category'):\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    df_cleaned = df.dropna(subset=[label])\n",
    "    df_cleaned = df_cleaned[~df['guests'].apply(lambda x: isinstance(x, str) and 'Somerford Keynes England Unit' in x)]\n",
    "    labels = df_cleaned[label]\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    return features, labels\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(features):\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms']\n",
    "    non_numeric_columns = [col for col in features.columns if col not in numerical_columns]\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features[numerical_columns] = imputer.fit_transform(features[numerical_columns])\n",
    "\n",
    "    features = features.drop(columns=non_numeric_columns)\n",
    "    return features\n",
    "\n",
    "# Load the dataset with 'Category' as the label\n",
    "features, labels = load_airbnb(label='Category')\n",
    "\n",
    "# Preprocess data\n",
    "features_preprocessed = preprocess_data(features)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_preprocessed, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = logreg_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.372463768115942\n",
      "Training Precision: 0.3745577885274984\n",
      "Training Recall: 0.372463768115942\n",
      "Training F1 Score: 0.3495261716768263\n",
      "Test Accuracy: 0.3265993265993266\n",
      "Test Precision: 0.3402601880738268\n",
      "Test Recall: 0.3265993265993266\n",
      "Test F1 Score: 0.30944688387685926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load Airbnb data for classification\n",
    "def load_airbnb_classification(label='Category'):\n",
    "    df = pd.read_csv('listing.csv')\n",
    "    df_cleaned = df.dropna(subset=[label])\n",
    "    df_cleaned = df_cleaned[~df['guests'].apply(lambda x: isinstance(x, str) and 'Somerford Keynes England Unit' in x)]\n",
    "    labels = df_cleaned[label]\n",
    "    features = df_cleaned.drop(columns=[label])\n",
    "    return features, labels\n",
    "\n",
    "def preprocess_data(features):\n",
    "    numerical_columns = ['Cleanliness_rating', 'Accuracy_rating', 'Communication_rating',\n",
    "                         'Location_rating', 'Check-in_rating', 'Value_rating',\n",
    "                         'guests', 'beds', 'bathrooms']\n",
    "    non_numeric_columns = [col for col in features.columns if col not in numerical_columns]\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features[numerical_columns] = imputer.fit_transform(features[numerical_columns])\n",
    "\n",
    "    features = features.drop(columns=non_numeric_columns)\n",
    "    return features\n",
    "\n",
    "# Train a logistic regression model\n",
    "def train_classification_model(X_train, y_train):\n",
    "    logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    return logreg_model\n",
    "\n",
    "def main():\n",
    "    # Load the dataset with 'Category' as the label\n",
    "    features, labels = load_airbnb_classification(label='Category')\n",
    "    \n",
    "    # Preprocess data\n",
    "    features_preprocessed = preprocess_data(features)   \n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_preprocessed, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Train a classification model\n",
    "    classification_model = train_classification_model(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on training and test sets\n",
    "    y_train_pred = classification_model.predict(X_train)\n",
    "    y_test_pred = classification_model.predict(X_test)\n",
    "    \n",
    "    # Compute performance measures for training set\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    recall_train = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    \n",
    "    # Compute performance measures for test set\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # Print performance measures\n",
    "    print(\"Training Accuracy:\", accuracy_train)\n",
    "    print(\"Training Precision:\", precision_train)\n",
    "    print(\"Training Recall:\", recall_train)\n",
    "    print(\"Training F1 Score:\", f1_train)\n",
    "    print(\"Test Accuracy:\", accuracy_test)\n",
    "    print(\"Test Precision:\", precision_test)\n",
    "    print(\"Test Recall:\", recall_test)\n",
    "    print(\"Test F1 Score:\", f1_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_classification_model_hyperparameters(model_class, param_grid, X_train, y_train, X_val, y_val):\n",
    "    # Create a GridSearchCV object with accuracy scoring\n",
    "    grid_search = GridSearchCV(model_class, param_grid, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and best hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    \n",
    "    # Evaluate the best model on the validation set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Create a dictionary of performance metrics\n",
    "    best_performance = {\n",
    "        \"validation_accuracy\": validation_accuracy,\n",
    "    }\n",
    "    \n",
    "    return best_model, best_hyperparameters, best_performance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
